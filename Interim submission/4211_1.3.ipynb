{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1.3</h1>\n",
    "In 1.3 we are required to compute the correlations between the gas consumption of every two households, and for each household, find out 5 other households with the highest correlation in gas consumption.\n",
    "\n",
    "This part of the code reads the <b><i>hourly_readings_final</i></b>.csv file which is generated in the previous section (1.2) and outputs <b><i>top_correlated_households</i></b>.csv. The main problem faced in this section is how the correlation should be computed. The initial idea was to calculate only based on hourly readings computed in 1.2 without considering time. However, many of the households do not have complete data, which means in some month, these households do not have any meter readings. Thus simply computing correlation based on hourly readings is not sufficient.\n",
    "\n",
    "The method used for 1.3 is to compute the average gas consumption for each household in each hour. The hourly consumption is computed first by comparing the readings between adjacent readings for the same household. After getting the hourly consumption, the mean of all readings in each hour is computed, as it is reasonable to say that by including more data points, the average can be more representative compared to taking a few data points. For each household, there are 24 data points for average hourly consumption, representing the 24 hours. Correlation matrix can be computed from the average hourly consumption, and the top 5 households with highest correlation can be found\n",
    "\n",
    "Another problem faced is the extremely limited data for household 6101, which has only one gas meter reading in the raw data file. Thus, it is omitted in the final calculation of correlations between households, since computing based on only one data point is not meaningful at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt \n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3\n",
    "# import result obtained from 1.2\n",
    "hourly_reading = pd.read_csv('./hourly_readings_final.csv')\n",
    "\n",
    "# get the list of dataids\n",
    "idList = hourly_reading['dataid'].drop_duplicates(keep = 'first')\n",
    "idList = idList.reset_index(drop = True)\n",
    "\n",
    "# split the column 'localminute' into 'day' and 'time'\n",
    "new_time = hourly_reading['localminute'].str.split(\" \", n = 1, expand = True)\n",
    "hourly_reading['day'] = new_time[0]\n",
    "hourly_reading['time'] = new_time[1]\n",
    "hourly_reading.drop(columns = ['localminute'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        dataid  meter_value         day      time\n",
      "400406    6101       114832  2016-01-20  21:00:00\n"
     ]
    }
   ],
   "source": [
    "# print out all readings from household 6101 to show the\n",
    "# insufficient information available for this household\n",
    "print(hourly_reading.loc[hourly_reading.dataid == 6101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-adea02922f2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhourly_reading\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m  \u001b[1;34m'0'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhr\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhourly_reading\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;31m#         compute the mean of hourly consumption for each household and insert into average_hourly_consumption dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0maverage_hourly_consumption\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhourly_reading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhourly_reading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataid\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'diffs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   2994\u001b[0m         \"\"\"\n\u001b[0;32m   2995\u001b[0m         new_values = super(Series, self)._map_values(\n\u001b[1;32m-> 2996\u001b[1;33m             arg, na_action=na_action)\n\u001b[0m\u001b[0;32m   2997\u001b[0m         return self._constructor(new_values,\n\u001b[0;32m   2998\u001b[0m                                  index=self.index).__finalize__(self)\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_map_values\u001b[1;34m(self, mapper, na_action)\u001b[0m\n\u001b[0;32m   1002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m         \u001b[1;31m# mapper is a function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/src\\inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-adea02922f2b>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhourly_reading\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m  \u001b[1;34m'0'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhr\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhourly_reading\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;31m#         compute the mean of hourly consumption for each household and insert into average_hourly_consumption dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0maverage_hourly_consumption\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhourly_reading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhourly_reading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataid\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'diffs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# add the 'diffs' column which shows the hourly consumption by each household\n",
    "# the function diff() computes the difference between the current data point and the previous data point\n",
    "# therefore the data points at the boundary (data id changes) are wrong and will be changed to NaN\n",
    "hourly_reading['diffs'] = hourly_reading['meter_value'].diff()\n",
    "mask = (hourly_reading.dataid != hourly_reading.dataid.shift(1))\n",
    "hourly_reading.loc[mask, 'diffs'] = np.nan\n",
    "\n",
    "# compute the average hourly consumption by each household\n",
    "# save all the values in the average_hourly_consumption dataframe created\n",
    "average_hourly_consumption = pd.DataFrame(np.random.randint(low = 0.0, high = 10.0, size = (24, len(idList))), columns = idList)\n",
    "for col in idList:\n",
    "    for hr in range (0, 23):\n",
    "#         set the criteria for selecting the data points\n",
    "        if hr < 10:\n",
    "            criterion = hourly_reading['time'].map(lambda x: (x[0] ==  '0') & (x[1] == str(hr)))\n",
    "        if hr >= 10:\n",
    "            criterion = hourly_reading['time'].map(lambda x: (x[0] == str(hr)[0]) & (x[1] ==  str(hr)[1]))\n",
    "#         compute the mean of hourly consumption for each household and insert into average_hourly_consumption dataframe\n",
    "        average_hourly_consumption.loc[hr, col] = hourly_reading.loc[(hourly_reading.dataid == col) & criterion]['diffs'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the correlation matrix of the new dataframe\n",
    "corr = average_hourly_consumption.corr()\n",
    "\n",
    "# remove the 1s in diagonal\n",
    "# as the correlation between a column and itself is always 1\n",
    "corr -= np.eye(corr.shape[0])\n",
    "\n",
    "# create a new dataframe with random values inserted\n",
    "top_corr = pd.DataFrame(np.random.randint(low = 0.0, high = 10.0, size = (5 * (len(idList) - 1), 3)), columns = ['HH1', 'HH2', 'corr']).reset_index(drop = True)\n",
    "\n",
    "# set 'corr' column data type as float64\n",
    "# since correlation value is a floating point between 0 and 1\n",
    "top_corr['corr'] = top_corr['corr'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all data ids in the correlation matrix\n",
    "# for each data id, find out the 5 data ids with the highest correlation values\n",
    "# collate all results in the top_corr dataframe\n",
    "count = 0\n",
    "for i in corr.columns[:]:\n",
    "    temp_corr = corr.nlargest(5, i)\n",
    "    \n",
    "#     since household 6101 has very limited information (only one available datum)\n",
    "#     it is discarded in the calculation of correlations between households\n",
    "    if i != 6101:\n",
    "        for j in range (0, 5):\n",
    "            top_corr.loc[count, 'HH1'] = i\n",
    "            top_corr.loc[count, 'HH2'] = temp_corr.index[j]\n",
    "            top_corr.loc[count, 'corr'] = temp_corr[i].iloc[j]\n",
    "            count += 1\n",
    "\n",
    "# export top_corr dataframe as csv file\n",
    "top_corr.to_csv('top_correlated_households.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
