{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 1.1 </h1>\n",
    "<body>\n",
    "<font size = \"2\" color = \"red\">->Put raw csv in same path as ipynb for smooth running of code </font><br><br>\n",
    "\n",
    "<font size = \"3\">This part of the code finds the number of houses in to whole dataset,<br>\n",
    "outputs <b><i>clean_df</i></b> csv for further processing,<br>\n",
    "marks out the time period of all malfunction meter</font><br>\n",
    "</body>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of houses = 157\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "import timeit\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "# start_time = timeit.default_timer() * 1000\n",
    "currentPath = str(Path().resolve())\n",
    "# Put raw csv in same \n",
    "path = currentPath + \"./dataport-export_gas_oct2015-mar2016.csv\"\n",
    "\n",
    "# Read in raw data and find \n",
    "df = pd.read_csv(path)\n",
    "data_id = df['dataid'].nunique()\n",
    "print(\"Number of houses =\", data_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-10-01 00:14:44\n",
      "Length of df: 1584823\n"
     ]
    }
   ],
   "source": [
    "# Sort data into order by id, if same id then by time\n",
    "df.sort_values([\"dataid\", \"localminute\"], ascending=[True, True], inplace = True)\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Cast localminute into proper time format for further processing\n",
    "df.localminute = df.localminute.str.slice(0,19)\n",
    "df.localminute = pd.to_datetime(df.localminute, infer_datetime_format = True, format = \"%Y/%m/%d %I:%M:%S %p\")\n",
    "print(df.localminute[0])\n",
    "print(\"Length of df:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of bad_array: 169130\n",
      "Length of to_drop: 1257748\n"
     ]
    }
   ],
   "source": [
    "# Types of malfunction\n",
    "# 1: data reported back when change in gas use is < 2 cubic foot\n",
    "# 2: data reported back new meter_value is smaller than old meter_value\n",
    "# 3: data reported back is >2, but time > 15s, threshold value for reporting malfunction will be 7 cubic foot/hr \n",
    "# (US household average daily usage = 168 cubic foot)\n",
    "# 4: However, continuous report of same reading from same id over 12hrs,\n",
    "# the first reading after 12hrs will be treated as good reading,\n",
    "# as the gas company will probably want to know whether is a meter malfunctioning\n",
    "# even though its reading did not change for a period of time\n",
    "\n",
    "# Progress bar cuz I always feel it is not working\n",
    "# f = FloatProgress(min=0, max=(len(df['dataid']) - 1))\n",
    "# display(f)\n",
    "\n",
    "# Create empty df and array for more efficient removal of item in df\n",
    "malfunction = pd.DataFrame(columns = [\"localminute\", \"dataid\", \"meter_value\"])\n",
    "bad_array = []\n",
    "to_drop = []\n",
    "\n",
    "prev_good = True\n",
    "_id = None\n",
    "_12hr = None\n",
    "# Sort malfunction with time period label\n",
    "# Assumption: the first data point is always correct as the 2nd pt is wrt to it, 3rd wrt to 2nd....etc\n",
    "# Append malfunction period and data to respective array\n",
    "for row in df.itertuples():\n",
    "    if(_id is None or _id != row.dataid):\n",
    "        prev_good = True\n",
    "        _id = row.dataid\n",
    "    # for estimating time take to process actual data\n",
    "    if (row.Index == 0):\n",
    "        continue\n",
    "    #1 and #2\n",
    "    if (((row.meter_value <= df.meter_value[row.Index-1])\n",
    "         and (row.dataid == df.dataid[row.Index-1])) \n",
    "        or ((row.localminute != df.localminute[row.Index-1]) \n",
    "            and (row.dataid == df.dataid[row.Index-1]) \n",
    "            and ((row.meter_value - df.meter_value[row.Index-1]) < 2))):\n",
    "        if(prev_good == True):\n",
    "            bad_array.append([_id, row.localminute, row.localminute])\n",
    "            to_drop.append(row.Index)\n",
    "            #4, update 12hr pt\n",
    "            _12hr = row.localminute\n",
    "        else:\n",
    "            #4  \n",
    "            if ((row.localminute - _12hr) >= pd.to_timedelta(\"12:00:00\")):\n",
    "                prev_good = True\n",
    "                continue\n",
    "            else:\n",
    "                bad_array[-1][2] = row.localminute\n",
    "                to_drop.append(row.Index)\n",
    "        prev_good = False\n",
    "    else:\n",
    "        prev_good = True\n",
    "        #3\n",
    "        if(((row.meter_value - df.meter_value[row.Index-1]) > 2) \n",
    "           and ((((row.localminute - df.localminute[row.Index-1]) / timedelta(hours = 1)) * 7) \n",
    "                > (row.meter_value - df.meter_value[row.Index - 1]))):\n",
    "            bad_array[-1][2] = row.localminute\n",
    "print(\"Length of bad_array:\", len(bad_array))\n",
    "print(\"Length of to_drop:\", len(to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of df: 327075\n",
      "length of malfunction: 169130\n"
     ]
    }
   ],
   "source": [
    "#Remove malfunction data to produce clean df\n",
    "df.drop(index = to_drop, inplace = True)\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# # Cast to int64\n",
    "# malfunction['dataid'] = malfunction['dataid'].astype(np.int64)\n",
    "# malfunction['meter_value'] = malfunction['meter_value'].astype(np.int64)\n",
    "\n",
    "# # Merge 2 df to compare diff, if one of the label value is different,\n",
    "# # value in _merge label will be different hence being able to differeniate the difference\n",
    "# df = pd.merge(df, malfunction, on=['localminute', 'dataid', 'meter_value'], how='outer', indicator=True)\\\n",
    "# .query(\"_merge != 'both'\")\\\n",
    "# .drop(['_merge'], axis=1)\\\n",
    "# .reset_index(drop=True)\n",
    "\n",
    "# Convert bad_array into df and transform it for shape to be correct\n",
    "malfunction = pd.DataFrame(bad_array, columns = ['dataid', 'start_time', 'end_time'])\n",
    "malfunction.T\n",
    "\n",
    "# Save part1 result into csv for easier access in part2\n",
    "df.to_csv('./clean_df.csv', index = False)\n",
    "malfunction.to_csv('./malfunction.csv', index = False)\n",
    "\n",
    "# pd.set_option('display.max_rows', 10000)\n",
    "\n",
    "# elapsed = timeit.default_timer() * 1000 - start_time\n",
    "# print(\"total: %ds\" %(elapsed/1000)) if ((elapsed > 5000) == True) else print(\"total: %dms\" %elapsed)\n",
    "print(\"length of df:\", len(df))\n",
    "print(\"length of malfunction:\", len(malfunction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1.2</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import timeit\n",
    "import datetime as dt \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327075"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gas_data = pd.read_csv(\"clean_df.csv\")\n",
    "len(gas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing data for easier computation in the following \n",
    "start_time = timeit.default_timer()\n",
    "gas_data.localminute = gas_data.localminute.str.slice(0,19)\n",
    "gas_data.localminute = pd.to_datetime(gas_data.localminute, infer_datetime_format = True, \n",
    "                                      format = \"%Y/%m/%d %I:%M:%S %p\");\n",
    "gas_data.localminute = gas_data.localminute.map(lambda x:x.replace(minute=0, second=0));\n",
    "gas_data['meter_value']=gas_data['meter_value'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gas_data=gas_data[gas_data['dataid']==35];\n",
    "ind=0;\n",
    "_hr=dt.timedelta(hours=1); #creating a constant timedelta object with value =1 hr for comparison\n",
    "temp_gas_hr=pd.DataFrame(columns=gas_data.columns);\n",
    "temp_gas_hr=gas_data;\n",
    "id_list=gas_data['dataid'].unique();#creating an id list for itertaion since only comparison of reading within id \n",
    "                                     #is meanningful\n",
    "\n",
    "missing_lm=[];\n",
    "missing_id=[];\n",
    "missing_val=[];\n",
    "\n",
    "for _id in id_list:\n",
    "    #generate hourly readings according to dataid\n",
    "    temp_gas_data=gas_data[gas_data['dataid']==_id];\n",
    "    temp_gas_data.reset_index(drop=True,inplace=True);\n",
    "    \n",
    "    for  row in temp_gas_data.itertuples():\n",
    "        if(row.Index==0):\n",
    "            prev_row=pd.Series(data=[row.localminute,row.dataid,row.meter_value]\n",
    "                               ,index=['localminute','dataid','meter_value']);\n",
    "            #unable to predict datapoints before the first available datapoint\n",
    "        else:\n",
    "            time_diff=row.localminute-prev_row.localminute;\n",
    "            #determine if there is any missing data before two consecutive available data\n",
    "            if(time_diff>_hr):\n",
    "                time_diff=int(time_diff.total_seconds()/3600);\n",
    "                #determine how many datapoints are missing\n",
    "                for j in range (1,time_diff):\n",
    "                    if ((row.meter_value-prev_row.meter_value)>4):\n",
    "                        #if the difference between two available datepoint is too large,\n",
    "                        #this means that there is missing distinct datapoints in between.\n",
    "                        acc_reading=float((row.meter_value-prev_row.meter_value)/time_diff);\n",
    "                    else:\n",
    "                        #if the difference is not large, the missing datapoint has value \n",
    "                        #equals to the previous datapoint\n",
    "                        acc_reading=0;\n",
    "                    time_change=dt.timedelta(hours=j);\n",
    "                    new_time=prev_row.localminute+time_change;\n",
    "                    missing_lm.append(new_time);\n",
    "                    missing_id.append(_id);\n",
    "                    missing_val.append(float(prev_row.meter_value+acc_reading*j));\n",
    "\n",
    "        prev_row=pd.Series(data=[row.localminute,row.dataid,row.meter_value]\n",
    "                               ,index=['localminute','dataid','meter_value']);\n",
    "       #make a copy the current available data for comparison in next iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the missing data with original data\n",
    "missing_data={'localminute':missing_lm,'dataid':missing_id,'meter_value':missing_val};\n",
    "missing_data=pd.DataFrame(missing_data,columns=gas_data.columns);\n",
    "temp_gas_hr=pd.concat([gas_data,missing_data]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 164s\n"
     ]
    }
   ],
   "source": [
    "temp_gas_hr=temp_gas_hr.sort_values(by=['dataid','localminute']);\n",
    "temp_gas_hr.drop_duplicates(['localminute','dataid'],keep='last',inplace=True); \n",
    "#for the same hour, if there is multiple readings, keep the highest value\n",
    "temp_gas_hr['meter_value']=temp_gas_hr['meter_value'].astype(int)\n",
    "print(\"total: %ds\" %(timeit.default_timer() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_gas_hr.to_csv('hourly_readings_final.csv',index=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color = \"red\">Run this cell only if generating graphs</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gas_hr=temp_gas_hr;\n",
    "# gas_hr=gas_hr[(gas_hr['localminute'].dt.year==2016)&(gas_hr['localminute'].dt.month==1)]\n",
    "# mon=2;\n",
    "# for _id in id_list:\n",
    "#     mon=2;\n",
    "#     temp_id_hr=gas_hr[gas_hr['dataid']==_id];\n",
    "#     while(len(temp_id_hr)==0):\n",
    "#         temp_id_hr=temp_gas_hr[(temp_gas_hr['localminute'].dt.year==2016)&(temp_gas_hr['localminute'].dt.month==mon)\n",
    "#                               &(temp_gas_hr['dataid']==_id)];\n",
    "#         mon=mon+1;\n",
    "#     temp_id_hr=temp_id_hr.reset_index(drop=True);\n",
    "#     t='Hourly reading of '+str(_id)+' of '+str(temp_id_hr.at[0,'localminute'].month)+' in '+str(temp_id_hr.at[0,'localminute'].year);\n",
    "#     fig=plt.figure(figsize=(15,15));\n",
    "#     plt.plot(temp_id_hr.localminute,temp_id_hr.meter_value);\n",
    "#     plt.xlabel('date hr/(hr)');\n",
    "#     plt.ylabel('meter_value'),\n",
    "#     plt.title(t,loc='center');\n",
    "#     plt.grid();\n",
    "#     t_fig=t+'.png';\n",
    "#     fig.savefig(t_fig);\n",
    "#     plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1.3</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt \n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.3\n",
    "hourly_reading = pd.read_csv('./hourly_readings_final.csv')\n",
    "\n",
    "# get the list of dataids\n",
    "idList = hourly_reading['dataid'].drop_duplicates(keep = 'first')\n",
    "idList = idList.reset_index(drop = True)\n",
    "\n",
    "len(idList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the gas meter readings based on data id\n",
    "# create a dataframe with only meter readings\n",
    "# the columns are all the different data ids\n",
    "rd = pd.DataFrame(columns = idList)\n",
    "for i in range(0, len(idList)):\n",
    "    rd[idList[i]] = hourly_reading.loc[hourly_reading.dataid == idList[i]]['meter_value'].reset_index(drop = True)\n",
    "\n",
    "# compute the correlation matrix of the new dataframe\n",
    "corr = rd.corr()\n",
    "\n",
    "# remove the 1s in diagonal\n",
    "# as the correlation between a column and itself is always 1\n",
    "corr -= np.eye(corr.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe with random values inserted\n",
    "top_corr = pd.DataFrame(np.random.randint(low = 0.0, high = 10.0, size = (5 * len(idList), 3)), columns = ['HH1', 'HH2', 'corr']).reset_index(drop = True)\n",
    "\n",
    "# set 'corr' column data type as float64\n",
    "# since correlation value is a floating point between 0 and 1\n",
    "top_corr['corr'] = top_corr['corr'].astype(float)\n",
    "\n",
    "# loop through all data ids in the correlation matrix\n",
    "# for each data id, find out the 5 data ids with the highest correlation values\n",
    "# collate all results in the top_corr dataframe\n",
    "count = 0\n",
    "for i in corr.columns[:]:\n",
    "    temp_corr = corr.nlargest(5, i)\n",
    "    for j in range (0, 5):\n",
    "        top_corr['HH1'].iloc[count] = i\n",
    "        top_corr['HH2'].iloc[count] = temp_corr.index[j]\n",
    "        top_corr['corr'].iloc[count] = temp_corr[i].iloc[j]\n",
    "        count += 1\n",
    "\n",
    "# export top_corr dataframe as csv file\n",
    "top_corr.to_csv('top_correlated_households.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
